{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch sparsezoo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading...: 100%|██████████| 349/349 [00:00<00:00, 182kB/s]\n",
      "downloading...: 100%|██████████| 695k/695k [00:00<00:00, 13.6MB/s]\n",
      "downloading...: 100%|██████████| 226k/226k [00:00<00:00, 7.33MB/s]\n",
      "downloading...: 100%|██████████| 196/196 [00:00<00:00, 113kB/s]\n",
      "downloading...: 100%|██████████| 1.18k/1.18k [00:00<00:00, 589kB/s]\n",
      "downloading...: 100%|██████████| 112/112 [00:00<00:00, 62.8kB/s]\n",
      "downloading...: 100%|██████████| 3.23k/3.23k [00:00<00:00, 1.59MB/s]\n",
      "downloading...: 100%|██████████| 1.03k/1.03k [00:00<00:00, 515kB/s]\n",
      "downloading...: 100%|██████████| 1.24G/1.24G [01:04<00:00, 20.6MB/s]\n",
      "downloading...: 100%|██████████| 346/346 [00:00<00:00, 182kB/s]\n",
      "downloading...: 100%|██████████| 522/522 [00:00<00:00, 192kB/s]\n",
      "downloading...: 100%|██████████| 1.24G/1.24G [01:10<00:00, 19.1MB/s]\n",
      "downloading...: 100%|██████████| 349/349 [00:00<00:00, 190kB/s]\n",
      "downloading...: 100%|██████████| 1.03k/1.03k [00:00<00:00, 522kB/s]\n",
      "downloading...: 100%|██████████| 695k/695k [00:00<00:00, 15.5MB/s]\n",
      "downloading...: 100%|██████████| 3.27k/3.27k [00:00<00:00, 1.58MB/s]\n",
      "downloading...: 100%|██████████| 332k/332k [00:00<00:00, 6.04MB/s]\n",
      "downloading...: 100%|██████████| 804/804 [00:00<00:00, 414kB/s]\n",
      "downloading...: 100%|██████████| 3.09k/3.09k [00:00<00:00, 1.92MB/s]\n",
      "downloading...: 100%|██████████| 1.24G/1.24G [00:35<00:00, 38.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "import sparsezoo\n",
    "model = sparsezoo.Model(\"zoo:bert-large-conll2003_wikipedia_bookcorpus-base\", download_path=\"./bert-large-conll2003\").download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"./bert-large-conll2003/training\"\n",
    "\n",
    "bert = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "bert = bert.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.31k/4.31k [00:00<00:00, 3.13MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.17k/2.17k [00:00<00:00, 1.46MB/s]\n",
      "Downloading readme: 100%|██████████| 7.59k/7.59k [00:00<00:00, 3.06MB/s]\n",
      "Downloading data: 100%|██████████| 84.1M/84.1M [00:02<00:00, 29.8MB/s]\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:06<00:00, 3714.42 examples/s] \n",
      "Generating test split: 100%|██████████| 25000/25000 [00:06<00:00, 3763.60 examples/s] \n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:08<00:00, 6155.64 examples/s] \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN = 128\n",
    "\n",
    "b_1 = tokenizer(dataset[3][\"text\"], return_tensors=\"pt\", max_length=SEQ_LEN, padding=\"max_length\", truncation=True)\n",
    "b_1[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 384])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_64 = tokenizer(dataset[3:3+64][\"text\"], return_tensors=\"pt\", max_length=SEQ_LEN, padding=\"max_length\", truncation=True)\n",
    "b_64[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 384])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_256 = tokenizer(dataset[3:3+256][\"text\"], return_tensors=\"pt\", max_length=SEQ_LEN, padding=\"max_length\", truncation=True)\n",
    "b_256[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 384])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_512 = tokenizer(dataset[3:3+512][\"text\"], return_tensors=\"pt\", max_length=SEQ_LEN, padding=\"max_length\", truncation=True)\n",
    "b_512[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp_dict in [b_1, b_64, b_256, b_512]:\n",
    "    for k in inp_dict:\n",
    "        inp_dict[k] = inp_dict[k].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- WARMUP -------\n",
      "------- STARTING B=1 -------\n",
      "torch.Size([1, 384])\n",
      "TOTAL_ITEMS = 100\n",
      "TOTAL_TIME = 1.84\n",
      "THROUGHPUT = 54.21\n",
      "------- STARTING B=64 -------\n",
      "torch.Size([64, 384])\n",
      "TOTAL_ITEMS = 320\n",
      "TOTAL_TIME = 5.42\n",
      "THROUGHPUT = 59.07\n",
      "------- STARTING B=256 -------\n",
      "torch.Size([256, 384])\n",
      "TOTAL_ITEMS = 1280\n",
      "TOTAL_TIME = 21.73\n",
      "THROUGHPUT = 58.91\n",
      "------- STARTING B=512 -------\n",
      "torch.Size([512, 384])\n",
      "TOTAL_ITEMS = 2560\n",
      "TOTAL_TIME = 44.80\n",
      "THROUGHPUT = 57.14\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "iterations_list = [\n",
    "    100,\n",
    "    5,\n",
    "    5,\n",
    "    5\n",
    "]\n",
    "\n",
    "inputs_dict = {\n",
    "    1: b_1,\n",
    "    64: b_64,\n",
    "    256: b_256,\n",
    "    512: b_512\n",
    "}\n",
    "\n",
    "print(f\"------- WARMUP -------\")\n",
    "for _ in range(5):\n",
    "    output = bert(**inputs_dict[1])\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "bert.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_size, iterations in zip(inputs_dict, iterations_list):\n",
    "        print(f\"------- STARTING B={batch_size} -------\")\n",
    "        print(inputs_dict[batch_size][\"input_ids\"].shape)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        for _ in range(iterations):\n",
    "            output = bert(**inputs_dict[batch_size])\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.perf_counter()\n",
    "        \n",
    "        total_items = iterations * batch_size\n",
    "        total_time = end - start\n",
    "        print(f\"TOTAL_ITEMS = {total_items}\")\n",
    "        print(f\"TOTAL_TIME = {total_time :0.2f}\")\n",
    "        print(f\"THROUGHPUT = {total_items / total_time :0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
